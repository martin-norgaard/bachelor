{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> This file runs both the calibration and the decompositioning of the model. In the settings section you may choose which country for which to run the analysis as well as whether to print results or output them in LaTeX format. If running the file for the first time consider setting install_packages = True. If running in Binder this is already taken care of. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calibration is run for all countries.\n",
    "## Choose country to output results for\n",
    "## \"BEL\", \"DNK\", \"FIN\", \"FRA\", \"GBR\", \"ITA\", \"JPN\", \"NLD\", or \"USA\"\n",
    "ISO = \"GBR\"\n",
    "\n",
    "## Choose whether to print Latex tables (True or False)\n",
    "show_results = True\n",
    "print_latex = False\n",
    "\n",
    "## Define where data is located\n",
    "data_path = \"data/data.csv\"\n",
    "\n",
    "## Required packages are numpy, pandas, scipy, statistics, itertools, and tabulate (if printing latex)\n",
    "install_packages = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calibration settings and assumptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moments = [\"AvgRet\",\"CapShare\",\"rf\",\"PD\",\"XK\",\"TFPgrowth\",\"PriceInvt\",\"PopGrowth\",\"EmpPop\"]\n",
    "parameters = [\"beta\",\"mu\",\"p\",\"delta\",\"alpha\",\"g_L\",\"g_Z\",\"g_Q\",\"N_bar\"]\n",
    "countries = [\"BEL\",\"DNK\",\"FIN\",\"FRA\",\"ITA\",\"JPN\",\"NLD\",\"GBR\",\"USA\"]\n",
    "startP1 = 1984\n",
    "endP1 = 1999\n",
    "startP2 = 2000\n",
    "endP2 = 2015\n",
    "b = 0.15\n",
    "theta = 12\n",
    "sigma = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if install_packages == True:   \n",
    "    !pip install numpy\n",
    "    !pip install pandas\n",
    "    !pip install scipy\n",
    "    !pip install statistics\n",
    "    !pip install more-itertools\n",
    "    !pip install tabulate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import scipy as sp\n",
    "from scipy import optimize\n",
    "from scipy.special import factorial\n",
    "import statistics as stat\n",
    "import itertools\n",
    "#!pip install tabulate\n",
    "from tabulate import tabulate\n",
    "\n",
    "class par: None\n",
    "class moms: None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set dictionary for data-series names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Dictionary for data-series\n",
    "data_series = {\n",
    "        \"AvgRet\": \"Average Return to Capital\",\n",
    "        \"CapShare\": \"Gross Capital Share\",\n",
    "        \"rf\": \"Risk Free Interest Rate\",\n",
    "        \"PopGrowth\": \"Population Growth\",\n",
    "        \"PriceInvt\": \"Investment Price Growth\",\n",
    "        \"PD\": \"Price-Dividend Ratio\",\n",
    "        \"TFPgrowth\": \"TFP Growth\",\n",
    "        \"XK\":\"Investment-Capital Ratio\",\n",
    "        \"EmpPop\": \"Employment-Population Ratio\",\n",
    "        \"Spread\": \"Spread\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define calculation of moments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_moments(country,s1,e1,s2,e2):    \n",
    "    df = pd.read_csv(data_path, sep=\";\", index_col=\"year\")\n",
    "    df = df[df[\"ISO\"]==country]\n",
    "    \n",
    "    start1 = int(s1)\n",
    "    end1 = int(e1)\n",
    "    start2 = int(s2)\n",
    "    end2 = int(e2)\n",
    "\n",
    "    #select relevant series, set year as index, create copy\n",
    "    df = df[['AvgRet','CapShare','rf', 'PopGrowth','PriceInvt','PD','TFPgrowth','XK','EmpPop']]\n",
    "    df = df.loc[start1:end2]\n",
    "\n",
    "    df_2 = pd.DataFrame(index=['AvgRet','CapShare','rf', 'PopGrowth','PriceInvt','PD','TFPgrowth','XK','EmpPop'])\n",
    "\n",
    "    # Calculate averages and insert to DataFrame\n",
    "    for var in df.columns.tolist():\n",
    "\n",
    "        df_2.loc[var,'p1'] = stat.mean(df.loc[s1:e1,var])\n",
    "        df_2.loc[var,'p2'] = stat.mean(df.loc[s2:e2,var])\n",
    "        #df_2.loc[var,'stdev1'] = stat.stdev(df.loc[1984:2000,var])\n",
    "        #df_2.loc[var,'stdev2'] = stat.stdev(df.loc[2001:2016,var])    \n",
    "        df_2.loc[var,'change'] = df_2.loc[var,'p2']-df_2.loc[var,'p1']\n",
    "   \n",
    "\n",
    "    return df_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### EQUATIONS IN IDENTIFICATION\n",
    "\n",
    "###### FOR PART 2\n",
    "def eq_footnote_15(par,moms):\n",
    "     return moms.TFPgrowth - (par.g_T-(1-moms.CapShare)*par.g_L-moms.CapShare*(par.g_T+par.g_Q))\n",
    "\n",
    "def eq_11(par,moms):\n",
    "    return (1+par.g_T) - (1+par.g_L)*(1+par.g_Z)**(1/(1-par.alpha))*(1+par.g_Q)**(par.alpha/(1-par.alpha))\n",
    "\n",
    "def eq_15(par,moms):\n",
    "    par.beta_star = 1/(1+par.r_star)\n",
    "    return moms.AvgRet - ((par.mu+par.alpha-1)/par.alpha)*(par.r_star + par.delta + par.g_Q/par.beta_star) \n",
    "\n",
    "def eq_18(par,moms):\n",
    "    return moms.XK - ((1+par.g_Q)*(1+par.g_T)-(1-par.delta))\n",
    "\n",
    "def eq_20(par,moms):\n",
    "    return moms.CapShare - (par.mu+par.alpha-1)/(par.mu)\n",
    "\n",
    "def eq_23(par,moms):\n",
    "    par.beta_star = 1/(1+par.r_star)\n",
    "    return moms.PD - par.beta_star*(1+par.g_T)/(1-par.beta_star*(1+par.g_T))\n",
    "### END OF EQ'S FOR PART 2\n",
    "\n",
    "###### FOR PART 3 \n",
    "def find_p(p,par,moms): # Change name from find_p to EQ-number at some point\n",
    "\n",
    "    update_misc(par)        \n",
    "    MOM2 = ((1-2*p)+p*np.exp(par.Bh*(1-par.theta)) + p*np.exp(par.B*(1-par.theta)))\n",
    "    MOM3 = ((1-2*p)+p*np.exp(par.Bh*(-par.theta)) + p*np.exp(par.B*(-par.theta))) \n",
    "\n",
    "    return moms.rf - (MOM2/(par.beta_star*MOM3)-1)\n",
    "\n",
    "def update_misc(par): # Help function for part 3\n",
    "\n",
    "    par.beta_star = 1/(1+par.r_star)\n",
    "    par.B = np.log(1-par.b)\n",
    "    par.Bh = np.log(1+par.b)\n",
    "    par.g_PC = (1+par.g_T)/(1+par.g_L)-1\n",
    "\n",
    "\n",
    "###### DEFINE CALIBRATION\n",
    "def calibrate(ISO,s,e,u,b,theta,sigma):\n",
    "    #Set country, start years and end years – when calling function, eventually\n",
    "    country = ISO\n",
    "    start = s\n",
    "    end = e\n",
    "    unique_id = u\n",
    "    \n",
    "    # a. shock size\n",
    "    par.b = b\n",
    "\n",
    "    # b. risk aversion coefficient\n",
    "    par.theta = theta\n",
    "\n",
    "    # c. IES, sigma = 1/IES\n",
    "    par.sigma = sigma\n",
    "\n",
    "    #Set data\n",
    "    df = pd.read_csv(data_path, sep=\";\", index_col=\"year\")\n",
    "    df = df[df[\"ISO\"]==country]\n",
    "\n",
    "    # Calc moments\n",
    "    moms.AvgRet = stat.mean(df.loc[start:end,\"AvgRet\"])/100 \n",
    "    moms.CapShare = stat.mean(df.loc[start:end,\"CapShare\"])/100 \n",
    "    moms.XK = stat.mean(df.loc[start:end,\"XK\"])/100\n",
    "    moms.PD = stat.mean(df.loc[start:end,\"PD\"])\n",
    "    moms.TFPgrowth = stat.mean(df.loc[start:end,\"TFPgrowth\"])/100\n",
    "    moms.rf = stat.mean(df.loc[start:end,\"rf\"])/100 #used in step 3\n",
    "    moms.PopGrowth = stat.mean(df.loc[start:end,\"PopGrowth\"])/100\n",
    "    moms.PriceInvt = -stat.mean(df.loc[start:end,\"PriceInvt\"])/100 # note: negativ value used\n",
    "    moms.EmpPop = stat.mean(df.loc[start:end,\"EmpPop\"])/100\n",
    "\n",
    "    # STEP 1: set parameters g_L, g_Q and N_bar directly\n",
    "    par.g_L = moms.PopGrowth\n",
    "    par.g_Q = moms.PriceInvt\n",
    "    par.N_bar = moms.EmpPop\n",
    "\n",
    "    # STEP 2\n",
    "\n",
    "    # Set initial guesses for parameters to be estimated in second part and solve equlation system\n",
    "\n",
    "    # a. parameters to estimate\n",
    "    par.names = ['g_Z','g_T','delta','alpha','r_star','mu']\n",
    "\n",
    "    # b. guess\n",
    "    par.mu = 1.01\n",
    "    par.delta = 0.025\n",
    "    par.alpha = 0.25\n",
    "    par.g_Z = 0.08 #0.02\n",
    "    par.r_star = 0.05\n",
    "    par.g_T = 0.04\n",
    "    x = set_x(par)\n",
    "\n",
    "    # c. solve\n",
    "    solution = optimize.fsolve(eq_system, x, args=(par,moms), full_output=0)\n",
    "    set_parameters(par,solution)\n",
    "\n",
    "    # STEP 3 – estimate beta and p\n",
    "\n",
    "\n",
    "    par.p = optimize.fsolve(find_p, 0.1, args=(par,moms), full_output=0)[0]\n",
    "    update_misc(par)\n",
    "    MOM =  ((1-2*par.p)+par.p*np.exp(par.Bh*(1-par.theta)) + par.p*np.exp(par.B*(1-par.theta)))**((1-par.sigma)/(1-par.theta)) \n",
    "    par.beta = par.beta_star/((1+par.g_PC)**(-par.sigma)*MOM);\n",
    "\n",
    "    df_estimates = []\n",
    "    for name in parameters:\n",
    "        df_estimates.append({'Parameter': name, unique_id:getattr(par,name)})\n",
    "\n",
    "    df_estimates = pd.DataFrame(df_estimates).set_index('Parameter')\n",
    "    \n",
    "    return df_estimates\n",
    "\n",
    "##### OTHER HELP FUNCTIONS\n",
    "def set_parameters(par,x):\n",
    "\n",
    "    for name,value in zip(par.names,x):\n",
    "        setattr(par,name,value)\n",
    "\n",
    "def set_x(par):\n",
    "\n",
    "    x = np.zeros(len(par.names))\n",
    "    for i,name in enumerate(par.names):\n",
    "        x[i] = getattr(par,name)\n",
    "\n",
    "    return x\n",
    "\n",
    "def eq_system(x,par,moms):\n",
    "\n",
    "    # a. set parameters\n",
    "    set_parameters(par,x)            \n",
    "\n",
    "    # c. evaluate equations\n",
    "    out = []\n",
    "    out.append(eq_footnote_15(par,moms))\n",
    "    out.append(eq_11(par,moms))\n",
    "    out.append(eq_15(par,moms))          \n",
    "    out.append(eq_18(par,moms))\n",
    "    out.append(eq_20(par,moms))\n",
    "    out.append(eq_23(par,moms))\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decomp(ISO):\n",
    "    # Get data\n",
    "    estimates = pd.DataFrame(index=parameters)\n",
    "    estimates.index.name = \"Name\"\n",
    "    estimates[\"P1\"] = all_estimates[ISO+\"_P1\"]\n",
    "    estimates[\"P2\"] = all_estimates[ISO+\"_P2\"] \n",
    "\n",
    "    # Make DataFrame with permutations\n",
    "    l_permutation = list(itertools.product([0, 1],[0, 1],[0, 1],[0, 1],[0, 1],[0, 1],[0, 1],[0, 1],[0, 1]))\n",
    "    df_permutation = pd.DataFrame(l_permutation,columns = parameters)\n",
    "    df_permutation[\"permsum\"] = df_permutation.sum(axis=1)\n",
    "\n",
    "    # Calculate weights\n",
    "    for parameter in parameters:\n",
    "        switch = df_permutation[parameter]\n",
    "        arr = np.array(df_permutation[\"permsum\"]-switch)\n",
    "        df_permutation[\"w_\" + parameter] = (factorial(arr)*factorial(8-arr))/factorial(9)\n",
    "\n",
    "    #Vary all parameters one by one and store values. Save in DataFrame df.\n",
    "    result = [(AvgRet(par,moms),CapShare(par,moms),rf(par,moms),PD(par,moms),ik(par,moms),TFPgrowth(par,moms),priceinvt(par,moms),growthpop(par,moms),EmpPop(par,moms))\n",
    "                for par.beta in [estimates.loc[\"beta\",\"P1\"],estimates.loc[\"beta\",\"P2\"]]\n",
    "                for par.mu in [estimates.loc[\"mu\",\"P1\"],estimates.loc[\"mu\",\"P2\"]]\n",
    "                for par.p in [estimates.loc[\"p\",\"P1\"],estimates.loc[\"p\",\"P2\"]]\n",
    "                for par.delta in [estimates.loc[\"delta\",\"P1\"],estimates.loc[\"delta\",\"P2\"]]\n",
    "                for par.alpha in [estimates.loc[\"alpha\",\"P1\"],estimates.loc[\"alpha\",\"P2\"]]\n",
    "                for par.g_L in [estimates.loc[\"g_L\",\"P1\"],estimates.loc[\"g_L\",\"P2\"]]\n",
    "                for par.g_Z in [estimates.loc[\"g_Z\",\"P1\"],estimates.loc[\"g_Z\",\"P2\"]]\n",
    "                for par.g_Q in [estimates.loc[\"g_Q\",\"P1\"],estimates.loc[\"g_Q\",\"P2\"]]\n",
    "                for par.N_bar in [estimates.loc[\"N_bar\",\"P1\"],estimates.loc[\"N_bar\",\"P2\"]]\n",
    "             ]\n",
    "    df = pd.DataFrame(result, columns=moments)\n",
    "\n",
    "    # Join permutations to results\n",
    "    df = df_permutation.join(df)\n",
    "\n",
    "    # Take means, etc, to create results\n",
    "    df_results = pd.DataFrame(columns=parameters)\n",
    "    df_results[\"moment\"] = moments\n",
    "    df_results = df_results.set_index(\"moment\",drop=True)\n",
    "\n",
    "    #Take means of all possible orders, conditional on one parameter. \n",
    "    for mom in moments:\n",
    "        for parm in parameters:\n",
    "            result = (df.loc[(df[parm] == 1),mom].mul(df[\"w_\"+parm]).sum()-df.loc[(df[parm] == 0),mom].mul(df[\"w_\"+parm]).sum())\n",
    "            df_results.loc[mom,parm] = result    \n",
    "\n",
    "    # Format results\n",
    "    df_results_formatted = df_results.copy()        \n",
    "    df_results_formatted = df_results_formatted.astype(float) # Convert all to floats (they appear to be strings?)\n",
    "    df_results_formatted.insert(0,'sum',df_results_formatted.sum(axis=1, skipna=True))    # Sum rows  \n",
    "\n",
    "    # Multiply all, except for PD, by 100\n",
    "    scalar = [1 if i==\"PD\" else 100 for i in df_results_formatted.index.tolist()]  #Create list, 1 for PD, 100 for all other\n",
    "    df_results_formatted = df_results_formatted.multiply(scalar,axis=0)\n",
    "    \n",
    "    # Construct Spread as AvgRet - rf\n",
    "    df_results_formatted.loc[\"Spread\",:] = df_results_formatted.loc[\"AvgRet\",:] - df_results_formatted.loc[\"rf\",:]\n",
    "\n",
    "\n",
    "    # Round and set padding zeros\n",
    "\n",
    "    return df_results_formatted\n",
    "\n",
    "# Define functions\n",
    "def misc(par,moms):\n",
    "    par.b = -np.log(1-0.15)\n",
    "    par.bh = -np.log(1+0.15)\n",
    "    par.sigma = 0.5\n",
    "    par.theta = 12\n",
    "    par.g_T = (1+par.g_L)*(1+par.g_Z)**(1/(1-par.alpha))*(1+par.g_Q)**(par.alpha/(1-par.alpha)) - 1\n",
    "    par.g_PC = (1+par.g_T)/(1+par.g_L) - 1   \n",
    "    par.MOM2 = ((1-2*par.p)+par.p*np.exp(-par.bh*(1-par.theta)) + par.p*np.exp(-par.b*(1-par.theta)))\n",
    "    par.MOM3 = ((1-2*par.p)+par.p*np.exp(-par.bh*(-par.theta)) + par.p*np.exp(-par.b*(-par.theta))) \n",
    "    par.MOM = (par.MOM2)**((1-par.sigma)/(1-par.theta))  \n",
    "    par.beta_star = par.beta * (1+par.g_PC)**(-par.sigma) * par.MOM\n",
    "\n",
    "#Define equations as functions of parameters only\n",
    "def growthpop(par,moms):\n",
    "    return par.g_L\n",
    "\n",
    "def priceinvt(par,moms):\n",
    "    return -par.g_Q\n",
    "\n",
    "def ik(par,moms):\n",
    "    return (1+par.g_Q)*(1+par.g_T)-(1-par.delta)\n",
    "\n",
    "def EmpPop(par,moms):\n",
    "    return par.N_bar\n",
    "\n",
    "def CapShare(par,moms):\n",
    "    return (par.mu+par.alpha-1)/(par.mu)\n",
    "\n",
    "def TFPgrowth(par,moms):\n",
    "    misc(par,moms)\n",
    "    moms.CapShare = (par.mu+par.alpha-1)/(par.mu)\n",
    "    return par.g_T-(1-moms.CapShare)*par.g_L-moms.CapShare*(par.g_T+par.g_Q)\n",
    "\n",
    "def AvgRet(par,moms):\n",
    "    misc(par,moms)\n",
    "    r_star = 1/par.beta_star - 1\n",
    "    return ((par.mu + par.alpha -1)/(par.alpha))*(r_star + par.delta + par.g_Q*(1+r_star))\n",
    "\n",
    "def rf(par,moms):\n",
    "    misc(par,moms)\n",
    "    return par.MOM2/(par.MOM3*par.beta_star)-1\n",
    "\n",
    "def PD(par,moms):\n",
    "    misc(par,moms)\n",
    "    return (par.beta_star*(1+par.g_T)/(1-par.beta_star*(1+par.g_T)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate moments for all countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_moments = pd.DataFrame(index=moments)\n",
    "for iso in countries:\n",
    "    dfx = calc_moments(iso,startP1,endP1,startP2,endP2)\n",
    "    all_moments[iso+\"_P1\"] = dfx[\"p1\"]\n",
    "    all_moments[iso+\"_P2\"] = dfx[\"p2\"]\n",
    "    all_moments[iso+\"_change\"] = dfx[\"change\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run calibration for all countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_estimates = pd.DataFrame(index=parameters)\n",
    "for iso in countries:\n",
    "    for p in [\"P1\",\"P2\"]:\n",
    "        if p == \"P1\": estimates = calibrate(iso,startP1,endP1,iso+\"_\"+p,b,theta,sigma)\n",
    "        if p == \"P2\": estimates = calibrate(iso,startP2,endP2,iso+\"_\"+p,b,theta,sigma)\n",
    "        all_estimates[iso+\"_\"+p] = estimates\n",
    "        class par: None\n",
    "        class moms: None\n",
    "        del estimates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print Latex table of moments for chosen country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if print_latex == 1:\n",
    "    \n",
    "    table = all_moments.loc[:,ISO+\"_P1\":ISO+\"_change\"]\n",
    "    \n",
    "    for var in table.columns.tolist()[:]:\n",
    "        table[var] = table[var].map('${:,.3f}$'.format) \n",
    "    \n",
    "    table.index = table.index.to_series().map(data_series)\n",
    "    latex = tabulate(table, tablefmt=\"latex_raw\")\n",
    "\n",
    "    print(\"\\\\begin{tabular}{lrrr}\")\n",
    "    print(\"\\\\toprule\")\n",
    "    print(\" & \\\\multicolumn{2}{c}{\\\\textit{Averages}} &  \\\\\\\\ \\\\cmidrule(lr){2-3} \")\n",
    "    print(\" & 1984 - 1999 & 2000 - 2015 & Change \\\\\\\\ \")\n",
    "    print(\"\\\\midrule\")\n",
    "    print(latex[29:-21])\n",
    "    print(\"\\\\bottomrule\")\n",
    "    print(\"\\end{tabular}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print Latex table of estimates for chosen country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if print_latex == 1:\n",
    "    #ISO = \"GBR\" # Uncomment to set country here\n",
    "    table = all_estimates.loc[:,ISO+\"_P1\":ISO+\"_P2\"].copy()\n",
    "    table['Parameter name'] = [\"Discount factor\",\"Markup\",\"Disaster probability\",\"Depreciation, pct.\",\"Cobb-Douglas parameter\",\"Population growth, pct.\",\"TFP growth, pct.\",\"Technological change, pct.\",\"Labour Supply\"]\n",
    "    table['Symbol'] = [\"$\\\\beta$\",\"$\\\\mu$\",\"$p$\",\"$\\\\delta$\",\"$\\\\alpha$\",\"$g_L$\",\"$g_Z$\",\"$g_Q$\",\"$\\\\bar{N}$\"]\n",
    "    table['Difference'] = table[ISO+\"_P2\"] - table[ISO+\"_P1\"]\n",
    "    table = table[[\"Parameter name\",\"Symbol\",ISO+\"_P1\",ISO+\"_P2\",\"Difference\"]]\n",
    "    table[ISO+\"_P1\"] = table[ISO+\"_P1\"].multiply([1,1,1,100,1,100,100,100,1])\n",
    "    table[ISO+\"_P2\"] = table[ISO+\"_P2\"].multiply([1,1,1,100,1,100,100,100,1])\n",
    "    table[\"Difference\"] = table[\"Difference\"].multiply([1,1,1,100,1,100,100,100,1])\n",
    "\n",
    "    for var in table.columns.tolist()[2:]:\n",
    "        table[var] = table[var].map('${:,.3f}$'.format)\n",
    "\n",
    "    latex = tabulate(table, tablefmt=\"latex_raw\", showindex=False)\n",
    "\n",
    "    print(\"\\\\begin{tabular}{lcccr}\")\n",
    "    print(\"\\\\toprule\")\n",
    "    print(\"& & & \\\\textit{Estimates} & \\\\\\\\ \\\\cmidrule(lr){3-5}\")\n",
    "    print(\"Parameter name & Symbol & \" + str(startP1) + \" - \" + str(endP1) + \" & \" + str(startP2) + \" - \" + str(endP2) + \" & Change \\\\\\\\\")\n",
    "    print(\"\\midrule\")\n",
    "    print(latex[30:-21])\n",
    "    print(\"\\\\bottomrule\")\n",
    "    print(\"\\\\end{tabular}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print Latex table of decomposition for chosen country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if print_latex == 1:\n",
    "    #ISO = \"GBR\" # Uncomment to set country here\n",
    "\n",
    "    # Set data values from calc_moments\n",
    "    mom_P1 = all_moments.loc[:,ISO+\"_P1\"]\n",
    "    mom_P2 = all_moments.loc[:,ISO+\"_P2\"]\n",
    "    \n",
    "    # Calculate spread\n",
    "    mom_P1.loc[\"Spread\"] = all_moments.loc[\"AvgRet\",ISO+\"_P1\"]-all_moments.loc[\"rf\",ISO+\"_P1\"]\n",
    "    mom_P2.loc[\"Spread\"] = all_moments.loc[\"AvgRet\",ISO+\"_P2\"]-all_moments.loc[\"rf\",ISO+\"_P2\"]\n",
    "    \n",
    "    formatted_decomp = decomp(ISO).copy()\n",
    "    formatted_decomp.insert(0,\"P2\",mom_P2)\n",
    "    formatted_decomp.insert(0,\"P1\",mom_P1)\n",
    "    \n",
    "    table = formatted_decomp\n",
    "    \n",
    "    for var in table.columns.tolist()[:]:\n",
    "        table[var] = table[var].map('${:,.2f}$'.format) \n",
    "    \n",
    "    table.index = table.index.to_series().map(data_series)\n",
    "    latex = tabulate(table, tablefmt=\"latex_raw\")\n",
    "    \n",
    "    latex = tabulate(formatted_decomp, showindex=True, tablefmt=\"latex_raw\")\n",
    "\n",
    "    print(\"\\\\begin{tabular}{lrrrrrrrrrrrr}\")\n",
    "    print(\"\\\\toprule\")\n",
    "    print(\" & \\multicolumn{3}{c}{\\\\textit{Data}} & \\multicolumn{9}{c}{\\\\textit{Decomposition of $\\\\Delta$}}  \\\\\\\\ \\\\cmidrule(lr){2-4} \\\\cmidrule(lr){5-13}\")\n",
    "    print(\" & P1 & P2 & $\\\\Delta$ & $\\\\beta$ & $\\\\mu$ & $p$ & $\\\\delta$ & $\\\\alpha$ & $g_L$ & $g_Z$ & $g_Q$ & $\\\\bar{N}$   \\\\\\\\\")\n",
    "    print(\"\\\\midrule\")\n",
    "    print(latex[38:-21])\n",
    "    print(\"\\\\bottomrule\")\n",
    "    print(\"\\\\end{tabular}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show estimated parameters for chosen country "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if show_results == 1: \n",
    "    table = all_estimates.loc[:,ISO+\"_P1\":ISO+\"_P2\"]\n",
    "    for var in table.columns.tolist()[:]:\n",
    "        table[var] = table[var].map('${:,.3f}$'.format)\n",
    "    \n",
    "    display(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show decomposition for chosen country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if show_results == 1:\n",
    "    \n",
    "    table = decomp(ISO)\n",
    "    for var in table.columns.tolist()[:]:\n",
    "        table[var] = table[var].map('${:,.2f}$'.format)\n",
    "    \n",
    "    display(table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
